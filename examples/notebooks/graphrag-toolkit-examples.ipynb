{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b70c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ./requirements.txt\n",
    "#pip install https://github.com/awslabs/graphrag-toolkit/releases/latest/download/graphrag-toolkit.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec68542",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit import LexicalGraphIndex, GraphRAGConfig\n",
    "from graphrag_toolkit.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.storage import VectorStoreFactory\n",
    "\n",
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "graph_store = GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE'])\n",
    "vector_store = VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE'])\n",
    "\n",
    "graph_index = LexicalGraphIndex(\n",
    "    graph_store, \n",
    "    vector_store\n",
    ")\n",
    "\n",
    "doc_urls = [\n",
    "    'https://docs.aws.amazon.com/neptune/latest/userguide/intro.html',\n",
    "    'https://docs.aws.amazon.com/neptune-analytics/latest/userguide/what-is-neptune-analytics.html',\n",
    "    'https://docs.aws.amazon.com/neptune-analytics/latest/userguide/neptune-analytics-features.html',\n",
    "    'https://docs.aws.amazon.com/neptune-analytics/latest/userguide/neptune-analytics-vs-neptune-database.html'\n",
    "]\n",
    "\n",
    "docs = SimpleWebPageReader(\n",
    "    html_to_text=True,\n",
    "    metadata_fn=lambda url:{'url': url}\n",
    ").load_data(doc_urls)\n",
    "\n",
    "graph_index.extract_and_build(docs, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec2a722",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit import LexicalGraphQueryEngine, format_source\n",
    "from graphrag_toolkit.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.storage import VectorStoreFactory\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "graph_store = GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE'])\n",
    "vector_store = VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE'])\n",
    "\n",
    "query_engine = LexicalGraphQueryEngine.for_traversal_based_search(\n",
    "    graph_store, \n",
    "    vector_store,\n",
    "    post_processors=format_source('url')\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"What are the differences between Neptune Database and Neptune Analytics?\")\n",
    "\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5a947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb78418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1f3184",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit import LexicalGraphQueryEngine, format_source\n",
    "from graphrag_toolkit.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.storage import VectorStoreFactory\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "graph_store = GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE'])\n",
    "vector_store = VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE'])\n",
    "\n",
    "query_engine = LexicalGraphQueryEngine.for_vector_guided_search(\n",
    "    graph_store, \n",
    "    vector_store\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"What are the differences between Neptune Database and Neptune Analytics?\")\n",
    "\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b6c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit import LexicalGraphIndex\n",
    "from graphrag_toolkit.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.storage import VectorStoreFactory\n",
    "from graphrag_toolkit.indexing.load import FileBasedChunks\n",
    "from graphrag_toolkit.indexing.build import Checkpoint\n",
    "\n",
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "file_based_chunks = FileBasedChunks('./extracted/')\n",
    "checkpoint = Checkpoint('extarction-checkpoint')\n",
    "\n",
    "graph_store = GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE'])\n",
    "vector_store = VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE'])\n",
    "\n",
    "graph_index = LexicalGraphIndex(\n",
    "    graph_store, \n",
    "    vector_store\n",
    ")\n",
    "\n",
    "doc_urls = [\n",
    "    'https://docs.aws.amazon.com/neptune/latest/userguide/intro.html',\n",
    "    'https://docs.aws.amazon.com/neptune-analytics/latest/userguide/what-is-neptune-analytics.html',\n",
    "    'https://docs.aws.amazon.com/neptune-analytics/latest/userguide/neptune-analytics-features.html',\n",
    "    'https://docs.aws.amazon.com/neptune-analytics/latest/userguide/neptune-analytics-vs-neptune-database.html'\n",
    "]\n",
    "\n",
    "docs = SimpleWebPageReader(\n",
    "    html_to_text=True,\n",
    "    metadata_fn=lambda url:{'url': url}\n",
    ").load_data(doc_urls)\n",
    "\n",
    "graph_index.extract(docs, handler=file_based_chunks, checkpoint=checkpoint, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa952bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit import LexicalGraphIndex\n",
    "from graphrag_toolkit.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.storage import VectorStoreFactory\n",
    "from graphrag_toolkit.indexing.load import FileBasedChunks\n",
    "from graphrag_toolkit.indexing.build import Checkpoint\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "file_based_chunks = FileBasedChunks('./extracted/')\n",
    "checkpoint = Checkpoint('build-checkpoint')\n",
    "\n",
    "graph_store = GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE'])\n",
    "vector_store = VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE'])\n",
    "\n",
    "graph_index = LexicalGraphIndex(\n",
    "    graph_store, \n",
    "    vector_store\n",
    ")\n",
    "\n",
    "graph_index.build(file_based_chunks, checkpoint=checkpoint, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c802bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.storage import VectorStoreFactory\n",
    "from graphrag_toolkit.indexing import sink\n",
    "from graphrag_toolkit.indexing.constants import PROPOSITIONS_KEY, DEFAULT_ENTITY_CLASSIFICATIONS\n",
    "from graphrag_toolkit.indexing.extract import LLMPropositionExtractor\n",
    "from graphrag_toolkit.indexing.extract import TopicExtractor\n",
    "from graphrag_toolkit.indexing.extract import GraphScopedValueStore\n",
    "from graphrag_toolkit.indexing.extract import ScopedValueProvider, DEFAULT_SCOPE\n",
    "from graphrag_toolkit.indexing.extract import ExtractionPipeline\n",
    "from graphrag_toolkit.indexing.build import Checkpoint\n",
    "from graphrag_toolkit.indexing.build import BuildPipeline\n",
    "from graphrag_toolkit.indexing.build import VectorIndexing\n",
    "from graphrag_toolkit.indexing.build import GraphConstruction\n",
    "\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "checkpoint = Checkpoint('advanced-construction-example', enabled=True)\n",
    "\n",
    "# Create graph and vector stores\n",
    "graph_store = GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE'])\n",
    "vector_store = VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE'])\n",
    "\n",
    "# Create extraction pipeline components\n",
    "\n",
    "# 1. Chunking using SentenceSplitter\n",
    "splitter = SentenceSplitter(\n",
    "    chunk_size=256,\n",
    "    chunk_overlap=20\n",
    ")\n",
    "\n",
    "# 2. Proposition extraction\n",
    "proposition_extractor = LLMPropositionExtractor()\n",
    "\n",
    "# 3. Topic extraction\n",
    "entity_classification_provider = ScopedValueProvider(\n",
    "    label='EntityClassification',\n",
    "    scoped_value_store=GraphScopedValueStore(graph_store=graph_store),\n",
    "    initial_scoped_values = { DEFAULT_SCOPE: DEFAULT_ENTITY_CLASSIFICATIONS }\n",
    ")\n",
    "\n",
    "topic_extractor = TopicExtractor(\n",
    "    source_metadata_field=PROPOSITIONS_KEY, # Omit this line if not performing proposition extraction\n",
    "    entity_classification_provider=entity_classification_provider # Entity classifications saved to graph between LLM invocations\n",
    ")\n",
    "\n",
    "# Create extraction pipeline\n",
    "extraction_pipeline = ExtractionPipeline.create(\n",
    "    components=[\n",
    "        splitter, \n",
    "        proposition_extractor,\n",
    "        topic_extractor\n",
    "    ],\n",
    "    num_workers=2,\n",
    "    batch_size=4,\n",
    "    checkpoint=checkpoint,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "# Create build pipeline components\n",
    "graph_construction = GraphConstruction.for_graph_store(graph_store)\n",
    "vector_indexing = VectorIndexing.for_vector_store(vector_store)\n",
    "        \n",
    "# Create build pipeline        \n",
    "build_pipeline = BuildPipeline.create(\n",
    "    components=[\n",
    "        graph_construction,\n",
    "        vector_indexing\n",
    "    ],\n",
    "    num_workers=2,\n",
    "    batch_size=10,\n",
    "    batch_writes_enabled=True,\n",
    "    checkpoint=checkpoint,\n",
    "    show_progress=True   \n",
    ")\n",
    "\n",
    "# Load source documents\n",
    "doc_urls = [\n",
    "    'https://docs.aws.amazon.com/neptune/latest/userguide/intro.html',\n",
    "    'https://docs.aws.amazon.com/neptune-analytics/latest/userguide/what-is-neptune-analytics.html',\n",
    "    'https://docs.aws.amazon.com/neptune-analytics/latest/userguide/neptune-analytics-features.html',\n",
    "    'https://docs.aws.amazon.com/neptune-analytics/latest/userguide/neptune-analytics-vs-neptune-database.html'\n",
    "]\n",
    "\n",
    "docs = SimpleWebPageReader(\n",
    "    html_to_text=True,\n",
    "    metadata_fn=lambda url:{'url': url}\n",
    ").load_data(doc_urls)\n",
    "\n",
    "# Run the build and exraction stages\n",
    "docs | extraction_pipeline | build_pipeline | sink "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f2aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
